{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess AI: MiniMax Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## math, randomization\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## copy board state prior to making move\n",
    "from copy import deepcopy\n",
    "\n",
    "## will need to keep track of time\n",
    "import time\n",
    "\n",
    "## library for chess UI\n",
    "import chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding the Chess Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define heuristic function(s) for the agent to use when evaluating a given game state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEval_Material: \n",
    "\n",
    "    def score(self, board, turn=chess.WHITE): \n",
    "\n",
    "        \"\"\" return a score for the given game state. \n",
    "        1. create dictionary of piece key: values\n",
    "        2. multiply dictionary by 1 or -1, depending on turn\n",
    "        3. retrieve distribution of pieces on board\n",
    "        4. sum values for these pieces\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. create dictionary of piece key: value pairs (white first)\n",
    "\n",
    "        white_scoring = {\n",
    "            'p': -1,\n",
    "            'n': -3,\n",
    "            'b': -3,\n",
    "            'r': -5,\n",
    "            'q': -9,\n",
    "            'k': 0,\n",
    "            'P': 1,\n",
    "            'N': 3,\n",
    "            'B': 3,\n",
    "            'R': 5,\n",
    "            'Q': 9,\n",
    "            'K': 0,\n",
    "        }\n",
    "\n",
    "        # 2. create negated version for black\n",
    "\n",
    "        black_scoring = {key: value * -1 for key, value in white_scoring.items()}\n",
    "\n",
    "        # 3. retrieve distribution of pieces on board\n",
    "\n",
    "        pieces = board.piece_map()\n",
    "\n",
    "        # 4. sum values for pieces on board\n",
    "\n",
    "        if turn == chess.WHITE:\n",
    "            scoring = white_scoring\n",
    "        else:\n",
    "            scoring = black_scoring\n",
    "        \n",
    "        score = 0\n",
    "        for key in pieces:\n",
    "            score += scoring[str(pieces[key])]\n",
    "\n",
    "        # output final score\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create class to represent chess player. details below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myChessPlayer:\n",
    "\n",
    "    \"\"\" Intelligent chess agent based on minimax algorithm. \n",
    "    DETAILS: \n",
    "    - Chess bot that chooses a move using a custom evaluation (i.e., heuristic) function. \n",
    "    - Utilizes the minimax algorithm with the following optimizations:\n",
    "      - alpha beta pruning\n",
    "      - iterative deepening \n",
    "    IMPLEMENTATION STEPS\n",
    "    - \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, depth=50, eval=myEval_Material()): \n",
    "        \n",
    "        \"\"\"Initializes your player.\n",
    "        Args: \n",
    "        - depth (int): depth of tree to which your agent will search\n",
    "        - eval (function): evaluation function used by your agent\n",
    "        \"\"\"\n",
    "\n",
    "        self.depth = depth\n",
    "        self.eval = eval\n",
    "\n",
    "    def move(self, game, time_left): \n",
    "        \n",
    "        \"\"\"Called to determine one move by your agent\n",
    "        Args:\n",
    "            game (Board): The board and game state.\n",
    "            time_left (function): Used to determine time left before timeout\n",
    "\n",
    "        Returns:\n",
    "            tuple: (int,int): Your best move\n",
    "        \"\"\"\n",
    "        best_move, utility = my_minimax(self, game, time_left, depth=self.depth)\n",
    "        return best_move\n",
    "    \n",
    "    def utility(self, game, my_turn, is_over=False, win=False):\n",
    "        \"\"\"You can handle special cases here (e.g. endgame)\"\"\"\n",
    "        if is_over:\n",
    "            if win:\n",
    "                return 1000\n",
    "            else:\n",
    "                return -1000\n",
    "        return self.eval.score(game, self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define minimax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_minimax(player, game, time_left, depth, alpha=float(\"-inf\"), beta=float(\"inf\"), my_turn=True, time_limit=0.97):\n",
    "    \"\"\"Implementation of the alphabeta algorithm.if is_over:\n",
    "            if win:\n",
    "                return 1000\n",
    "            else:\n",
    "                return -1000\n",
    "\n",
    "    Args:\n",
    "        player (CustomPlayer): This is the instantiation of CustomPlayer()\n",
    "            that represents your agent. It is used to call anything you need\n",
    "            from the CustomPlayer class (the utility() method, for example,\n",
    "            or any class variables that belong to CustomPlayer())\n",
    "        game (Board): A board and game state.\n",
    "        time_left (function): Used to determine time left before timeout\n",
    "        depth: Used to track how deep you are in the search tree\n",
    "        alpha (float): Alpha value for pruning\n",
    "        beta (float): Beta value for pruning\n",
    "        my_turn (bool): True if you are computing scores during your turn.\n",
    "\n",
    "    Returns:\n",
    "        (tuple, int): best_move, val\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    my_states = set()\n",
    "    my_states_dict = {}\n",
    "\n",
    "    their_states = set()\n",
    "    their_states_dict = {}\n",
    "\n",
    "    def search_ab(game, d, alpha, beta, my_turn):\n",
    "\n",
    "        if time.time() - start_time >= time_limit:\n",
    "            return (None, -1000000000)\n",
    "\n",
    "        if my_turn:\n",
    "            best_move, best_score = max_ab(game, d, alpha, beta)\n",
    "        else:\n",
    "            best_move, best_score = min_ab(game, d, alpha, beta)\n",
    "\n",
    "        return (best_move, best_score)\n",
    "\n",
    "    def max_ab(game, d, alpha, beta):\n",
    "\n",
    "        ## maximize on player's turn\n",
    "        possible_moves = list(game.generate_legal_moves())\n",
    "\n",
    "        ## tracker variables\n",
    "        best_move = None\n",
    "        best_score = -1000000\n",
    "\n",
    "        for move in possible_moves:\n",
    "\n",
    "            new_game, is_over, _ = game.forecast_move(move)\n",
    "\n",
    "            if new_game in my_states:\n",
    "                score = my_states_dict[move]\n",
    "\n",
    "            ## if move results in game over, or if depth limit has been reached, evaluate game state\n",
    "            elif is_over or d == 1:\n",
    "                score = player.utility(new_game, my_turn, is_over, True)\n",
    "\n",
    "            ## if game is in progress, call min function\n",
    "            else:\n",
    "                _, score = search_ab(new_game, d-1, alpha, beta, my_turn=False)\n",
    "\n",
    "            if new_game not in my_states:\n",
    "                my_states.add(move)\n",
    "                my_states_dict[move] = score\n",
    "\n",
    "            ## alpha-beta pruning\n",
    "            if score >= beta:\n",
    "                return (move, score)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_move = move\n",
    "                alpha = max(score, alpha)\n",
    "\n",
    "        return (best_move, best_score)\n",
    "\n",
    "    def min_ab(game, d, alpha, beta):\n",
    "\n",
    "        ## minimize on opponent's turn\n",
    "        possible_moves = game.get_opponent_moves(player)\n",
    "\n",
    "        ## tracker variables\n",
    "        best_move = None\n",
    "        best_score = 1000000\n",
    "\n",
    "        for move in possible_moves:\n",
    "\n",
    "            new_game, is_over, _ = game.forecast_move(move)\n",
    "\n",
    "            if new_game in their_states:\n",
    "                score = their_states_dict[move]\n",
    "\n",
    "            ## if game is over, evalate game state\n",
    "            elif is_over or d == 1:\n",
    "                score = player.utility(new_game, my_turn, is_over, False)\n",
    "\n",
    "            ## if game is in progress, call max function\n",
    "            else:\n",
    "                _, score = search_ab(new_game, d-1, alpha, beta, my_turn=True)\n",
    "\n",
    "            if new_game not in their_states:\n",
    "                their_states.add(new_game)\n",
    "                their_states_dict[new_game] = score\n",
    "\n",
    "            ## alpha-beta pruning\n",
    "            if score <= alpha:\n",
    "                return (move, score)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_move = move\n",
    "                beta = min(score, beta)\n",
    "\n",
    "        return (best_move, best_score)\n",
    "\n",
    "    final_move = None\n",
    "    final_score = -10000000\n",
    "\n",
    "    for d in range(3, depth+1):\n",
    "        if time.time() - start_time >= time_limit:\n",
    "            break\n",
    "        for move in game.get_player_moves(player):\n",
    "            move, score = search_ab(game, d, alpha, beta, my_turn=True)\n",
    "            if score > final_score:\n",
    "                final_move = move\n",
    "                final_score = score\n",
    "\n",
    "    return (final_move, final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_game = chess.Board()\n",
    "\n",
    "my_eval = myEval_Material()\n",
    "\n",
    "my_eval.score(my_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Move.from_uci('g8h6')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimax(game, chess.BLACK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Move.from_uci('g1h3')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.push_san('g1h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_N(board, turn):\n",
    "\n",
    "    moves = list(board.generate_legal_moves())\n",
    "    scores = []\n",
    "    for move in moves:\n",
    "        test_board = deepcopy(board)\n",
    "        scores.append(eval_board(test_board, turn))\n",
    "\n",
    "    best_move = moves[np.argmax(scores)]\n",
    "\n",
    "    if N>1:\n",
    "\n",
    "        board.push(best_move)\n",
    "        temp_best_move = minimax_N(board)\n",
    "    \n",
    "    return(best_move)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
